% This is LLNCS.DOC the documentation file of
% the LaTeX2e class from Springer-Verlag
% for Lecture Notes in Computer Science, version 2.4
\documentclass{llncs}
\usepackage{llncsdoc}
%

% Variable definitions
\newcommand{\variantSpark}{{\sc VariantSpark}}
\newcommand{\kMeans}{\textit{k}-means}
\newcommand{\ARI}{adjusted Rand index}



\begin{document}

\newcounter{save}\setcounter{save}{\value{section}}
{\def\addtocontents#1#2{}%
\def\addcontentsline#1#2#3{}%
\def\markboth#1#2{}%
%
\title{Using VariantSpark to learn population structure from genomic profiles}

\author{Aidan R. O'Brien\inst{1,2}, Jason Ross\inst{1}, Robert Dunne\inst{1}, Firoz Anwar\inst{1}, \and Denis C. Bauer\inst{1}}

\institute{
CSIRO, 11 Julius Av, 2113, Sydney, Australia \\
\and
School of Biomedical Sciences and Pharmacy, Faculty of Health, University of Newcastle, 2308, Newcastle, Australia \\
}

\maketitle
%
\begin{abstract}
This paragraph shall summarize the contents of the paper
in short terms.
\end{abstract}
%
\section{Introduction}
%

%TODO other examples?

Determining a person's ethnicity has become important for medical applications, such as HLA allele genotyping from SNP
information~\cite{Zheng2014}. Such clinical application are severely hampered for patients where accurate population
association is unknown due to a diverse migrational background. Determining the population association from genomic
information may provide vital insights for treatment and diagnostic in such cases.

Aiding this task, we developed \variantSpark~\cite{OBrien}, a \kMeans{} approach using {\sc Spark}'s machine learning
library, {\sc MLlib}, which is capable of clustering variants from whole genome sequencing data.  We demonstrate its use
by clustering samples from the 1000 Genomes Project~\cite{1KG2012}.  \marginpar{TODO add value of the kmeans method on
  the full dataset (the equivalent of the ARI=0.84) Denis: correct/total happened to be 0.84 too ? or are you quoting
  here the ARI ? I want to have the same accuracy measure as reported by bdgenomics for all comparisons in this paper,
  also it goes between 0 and 100 right ?}

Using \kMeans{} we observed a perfect separation for the super populations African (AFR), East Asian (EAS) and European
(EUR), however when adding the fourth super-population group, American (AMR), we observe that only a subset of the AMR
individual form an independent cluster while the majority falls into the EUR cluster, resulting in an accuracy of 0.84,
with -1 being random and 1 a perfect clustering.  We argue that the suboptimal clustering is a result of using an
unsupervised method rather than an insufficient number of genomic markers~\cite{Patterson2006} and hence hypothesise
that a supervised machine learning method may be capable of separating these subgroups of low genetic divergence.
Indeed, bigdata genomics recently investigated the supervised method, deep learning, for clustering the 1000 genomes
data by ethnicity~\cite{Ferguson}.

In this paper we therefore systematically evaluate supervised and unsupervised methods for determining population
association and compare our results to the ones obtained using deep learning.
\marginpar{TODO Rob can you think of a better description of what it does}
One of the simplest supervised machine learning methods is logistic regression (LR), which creates a decision boundary
by fitting a linear combination of the feature variables.  It is therefore able to adjust the weight of the individual
genotypes to increase the accuracy of the multi-class prediction.


 
\marginpar{TODO do we need to cite ~\cite{Bureau2005,Yoo2012,Qi2012}.}  We also investigate more complex supervised
approaches, namely Random Forest (RF), as for example Locke {\it et al.}~\cite{Locke2015} showed in a recent meta-study
around genetic susceptibility of obesity that only five of the 97 genomic loci have an independent association signal
the rest seem to jointly predict the complex metabolic phenotype.  We therefore investigate whether ethnicity is a
similarly complex phenotype that requires higher order dependencies between features to be taken into
account. %, as done by RF and DL.
\marginpar{TODO Rob do you want to add two sentences about RF and DL and the respective benefits (ideally with respect
  to the multi variable interactions and RF benefit of being hard to overfit).  Using conventional machine learning
  analysis to elucidate this additive effects is challenging as there are not enough samples to robustly fit the model
  over such a high-dimensional feature space~\cite{Chen2012}.  As a result machine learning methods such as random
  forests (RF) have become popular as the underlying decision trees are build from a subsets of the features, which make
  the approach robust against overfitting issues~\cite{Breiman2001}.  However, training a supervised learning method on
  such an expansive dataset as the 1000 genomes is computationally challenging and traditional massively parallel
  approaches to data processing are not easily applicable to machine learning tasks, as they iteratively refine models
  based on information from the full dataset.}

We therefore use {\sc Spark} through our recently developed \variantSpark~\cite{OBrien} framework, which allows us to
apply RF in the {\sc MLlib} library to the variant file in the standard Variant Call Format (VCF) format.  Please note
that unlike {\sc Hadoop}, {\sc Spark} allows a more flexible software design to utilise node-parallelisation and offers
in-memory cashing, both critical components for efficient ``big learning" tasks.

To demonstrate \variantSpark's capability, we determine the cross-validation accuracy of the supervised multivariate RF
method and compare it against the simple supervised method LR as well as the unsupervised \kMeans{} in the first
section.  In the second section we compare LR and \kMeans{} against the reported accuracy of the supervised multivariate
DL method.  In section three we record the accuracy of LR and \kMeans{} on the full dataset set using all populations.
In the last section we discuss the memory consumptions and runtime of LR compared to \kMeans{}.


\marginpar{TODO check accuracy of titles}
\section{Results}

\subsubsection{Random Forest does not scale to whole genome analysis and is outperformed by logistic regression}
In this section we compare RF against \kMeans\ and the LR.  
\marginpar{TODO elaborate on the error} 
Despite using {\sc Spark} and {\sc MLlib}, RF is not able to scale to the full dataset of 1000 individuals and 40
Million variables, due to XXX.  We therefore use only chromosome 22 for the comparison in this section.  We train a RF
and LR on this subset of genomic profiles from the 1000 Genomes data using the annotated labels of all
super-populations.  We perform 5-fold cross-validation and report the mean accuracy over all training and testing folds
along with the standard error.  We also perform 5 runs of \kMeans{} with 4 clusters and report the mean accuracy of the
resulting models along with the standard error.

\marginpar{TODO elaborate on accuracy measures}
As reported in our earlier work, \kMeans\ is not able to fit the dataset accurately (XX\%, ARI=Y), see table~\ref{RF}.
RF achieves a higher accuracy (XX\%, ARI=Y) but is outperformed by the simple logistic regression (XX\%, ARI=Y).
This indicates that a multivariate approach may not be needed to accurately fit ethnicity. 


\begin{table}
\caption{Cross-validated results, mean accuracy (and standard error) on variants from chromosome 22 of 4 super-populations.}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & test folds & training folds & hold out \\
RF  & X (Y) & X (Y) & X (Y) \\
\kMeans & X (Y) & X (Y) & X (Y) \\
LR & X (Y) & X (Y) & X (Y) \\
\noalign{\smallskip}
\hline
\label{RF}
\end{tabular}
\end{center}
\end{table}




\marginpar{TODO report bd's accuracy measure as the main measure (add ARI as the additional information linking to our
  paper)}
\subsubsection{Logistic regression and \kMeans{} capture the population better than deep learning in a three population test}
In this section we investigate whether the multivariate approach, deep learning, is able to achieve a better result than
RF by again comparing it against \kMeans{} and logistic regression.  We compare against the reported accuracy of the
deep learning approach using the {\sc ADAM} framework~\cite{Massie2013} as reported on their webpage~\cite{Ferguson}.
As the reported results were performed on only three of the 14 populations, we hence restrict our comparison also to ASW
(Americans of African Ancestry in SW USA), CHB (Han Chinese in Bejing, China), and GBR (British in England and
Scotland).

The mean error for our \kMeans clustering models is approximately XXX. This is similar to the deep-learning approach
where they achieved an accuracy of 99\% (two misclassified individuals). Our supervised logistic regression approach,
however, improves upon this result.  With this approach, we achieve an accuracy of 100\%. This is the average across
five folds, with a standard error of 0. This is on the above three populations, ASW, CHB and GBR, that belong to the
super-populations, AFR, EAS and EUR, respectively.  As we mention in the introduction, we observed a perfect clustering
result when we cluster the entirety of these three super-populations, with an ARI of 1.0. However, when we introduce the
fourth super-population into the mix, AMR, the ARI drops to 0.84.


Given the perfect result when building the logistic regression model on this small subset of data, we expand our dataset
to include every population from the 1000 Genomes Project phase1 dataset.

Although we see two of our five runs meet the accuracy of the deep-learning approach, where they achieved an accuracy of
99\% (or ARI of 0.975, with two misclassified individuals), our logistic regression approach demonstrates a consistent
improvement.  With this approach, we achieve an accuracy of \(99.997 \pm 0.003\) across five folds.

To reiterate, these results are from the three populations, ASW, CHB and GBR, that belong to the super-populations, AFR,
EAS and EUR, respectively.  As we mention in the introduction, we observed a perfect clustering result when we cluster
the entirety of these three super-populations (rather than one population from each), with an ARI of 1.0. However, when
we introduce the fourth super-population into the mix, AMR, the ARI drops to 0.84.  Given the perfect result from the
logistic regression models on the three populations, and the improvement over \kMeans{}, we proceed with logistic
regression on the four super-populations.

\marginpar{TODO[say that this may be a too easy dataset to benchmark the performance differences between kmeans and RF
  (hence the full dataset needed)]}

\begin{table}
\caption{Cross-validated results, mean accuracy (and standard error) on 3 populations.}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & test folds & training folds & hold out \\
RF  & X (Y) & X (Y) & X (Y) \\
\kMeans & X (Y) & X (Y) & X (Y) \\
deep learning & X (Y) & X (Y) & X (Y) \\
\noalign{\smallskip}
\hline
\end{tabular}
\end{center}
\end{table}

\subsubsection{Logistic regression is more accurate than \kMeans{} in capturing the full population structure}
In this section we train and test our two methods on the full dataset of 14 populations and assess the accuracy with respect to the accurate classification into the 4 super-populations.
Using 10-fold cross-validation to assess the logistic regression classification results, we observe an average ARI of \(0.93 \pm{} XX\). This is an improvement on our previous result from \kMeans{} clustering the same dataset
where we observed an ARI of \(0.83\).
We also record the precision and recall for each of the groups, and observe that for each classification, and both values are always 1.0 for the EAS super-population. This demonstrates that each logistic regression model was able to classify every EAS individual correctly while not including any false positives in this group.
For the AMR group, however, we consistently observed a relatively low precision (\(0.85\pm{} XX \)). This was generally due to individuals from the EUR super-population being misclassified as AMR. As a result, this led to EUR having a relatively low recall (\(0.9 \pm XX \)).
Although not present in the result of every fold, another observation is that AFR individuals would sometimes be misclassified as AMR. In all ten folds, we didn't observe AFR being classified as EUR, and vice-verse, nor AMR individuals being misclassified as another super-population.
These results demonstrate the diversity, or relative difference of some of the groups. 

\marginpar{TODO [Discuss supervised vs unsupervised]} \marginpar{TODO can you drill down to the population clusters and
  see if and where the best performing method still makes mistakes - this will help in the conclusion to argue that
  actually the labels are wrong rather than the method not being able to capture the structure (e.g. say if AMR are
  mixed in with GBR TSI)}

\begin{table}
\caption{Cross-validated results, mean accuracy (and standard error) on the 4 super-populations.}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & test folds & training folds & hold out \\
RF  & X (Y) & X (Y) & X (Y) \\
\kMeans & X (Y) & X (Y) & X (Y) \\
\noalign{\smallskip}
\hline
\end{tabular}
\end{center}
\end{table}







\subsubsection{\kMeans{} clustering is faster and consumes less memory than random forests}

Although memory requirements scale linearly with 

\marginpar{TODO [write up the observations and argue why one is less resource hungry than the other one]}


\begin{table}
\caption{Runtime and memory consumption on the 4 super-populations}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & nodes & runtime & memory \\
RF  & X (Y) & X (Y) & X (Y) \\
\kMeans & X (Y) & X (Y) & X (Y) \\
\noalign{\smallskip}
\hline
\end{tabular}
\end{center}
\end{table}




\section{Conclusion}
In this paper we systematically investigated the performance of supervised and unsupervised methods for determining the
ethnicity from whole genome variant data.  We found that a supervised method, logistic regression, outperforms the
unsupervised approach, \kMeans{} (XX vs YY).  We also found that ethnicity can be better predicted by the simple
logistic regression method compared to the multivariate approaches such as random forest or deep learning as reported by
Big Data Genomics using the ADAM framework (XX vs Y1 and Y2, respectively).  Furthermore, we observe a limitation within
Java, which limits the random forest implementation of {\sc Spark}'s {\sc MLlib} to XX features for the 1069 individuals
of the 1000 genome project.  This property would limit the 100,000 genome project to using only YY features for their
70,000 individuals, when using the same random forest implementation.  We conclude that while logistic regression
outperforms all other methods it remains unable to accurately classify individuals from [Sub-populations] from the AMR
super-population.  We therefore ague that the remaining mixture in X is reflective of the migrational background and
hence the underlying genomic profile of Y is accurately similar to X.  This may be an important observation for medical
applications that need accurate population association.



\bibliographystyle{plain}
\marginpar{TODO you need to find a way of shortening the Locket paper author list}
\bibliography{recomb}  

\end{document}
