% This is LLNCS.DOC the documentation file of
% the LaTeX2e class from Springer-Verlag
% for Lecture Notes in Computer Science, version 2.4
\documentclass{llncs}
\usepackage{llncsdoc}
\usepackage{placeins}
\usepackage{hyperref}
\usepackage{amsmath}
%

% Variable definitions
\newcommand{\variantSpark}{{\sc VariantSpark}}
\newcommand{\kMeans}{\textit{k}-means }
\newcommand{\ARI}{adjusted Rand index}



\begin{document}

\newcounter{save}\setcounter{save}{\value{section}}
{\def\addtocontents#1#2{}%
\def\addcontentsline#1#2#3{}%
\def\markboth#1#2{}%
%
\title{Using VariantSpark to learn population structure from genomic profiles}

\author{Aidan R. O'Brien\inst{1,2}, Jason Ross\inst{1}, Robert Dunne\inst{1}, Firoz Anwar\inst{1}, \and Denis C. Bauer\inst{1}}

\institute{
CSIRO, 11 Julius Av, 2113, Sydney, Australia \\
\and
School of Biomedical Sciences and Pharmacy, Faculty of Health, University of Newcastle, 2308, Newcastle, Australia \\
}

\maketitle
%
\begin{abstract}
Using our 
We apply various machine learning algorithms to the 1092 individuals in the 1000 Genomes Project dataset.
Although each algorithm we investigate can cluster individuals from three populations with near perfect accuracy,
we find logistic regression to be superior. Comparing  With the entire dataset, 

\end{abstract}
%
\section{Introduction}
%

%TODO other examples?

\marginpar{I don't understand this. Can't you just ask a patient about their ancestry?}
Determining a person's ethnicity has become important for medical applications, such as HLA allele genotyping from SNP
information~\cite{Zheng2014}. Such clinical application are severely hampered for patients where accurate population
association is unknown due to a diverse migrational background. Determining the population association from genomic
information may provide vital insights for treatment and diagnostic in such cases.

Aiding this task, we developed \variantSpark~\cite{OBrien}, a \kMeans{} approach using {\sc Spark}'s machine learning
library, {\sc MLlib}, which is capable of clustering variants from whole genome sequencing data.  We demonstrate its use
by clustering samples from the 1000 Genomes Project~\cite{1KG2012}. 

Using \kMeans{} we observed a perfect separation for the super populations African (AFR), East Asian (EAS) and European
(EUR), however when adding the fourth super-population group, American (AMR), we observe that only a subset of the AMR
individual form an independent cluster while the majority falls into the EUR cluster.  We quantified this by calculating
the \ARI\ ( ARI), which compares the predicted and annotated labels. \kMeans achieved an ARI of 0.84, with -1 being
random and 1 a perfect clustering.  We argue that the suboptimal clustering is a result of using an unsupervised method
rather than an insufficient number of genomic markers~\cite{Patterson2006} and hence hypothesise that a supervised
machine learning method may be capable of separating these subgroups of low genetic divergence.  Indeed, bigdata
genomics recently investigated the supervised method, deep learning, for clustering the 1000 genomes data by
ethnicity~\cite{Ferguson}.  \marginpar{``bigdata genomics'' seems to be a domain name \url{http://bdgenomics.org/} --
  how should we cite this}

In this paper we therefore systematically evaluate supervised and unsupervised methods for determining population
association and compare our results to the ones obtained using deep learning.
%\marginpar{TODO Rob can you think of a better description of what it does}
One of the simplest supervised machine learning methods is logistic regression (LR), which creates a decision boundary
by fitting a linear combination of the feature variables.  In this appliction it is not fesible to model interactions,
so the model is retricted to main effects. 

%\marginpar{TODO do we need to cite ~\cite{Bureau2005,Yoo2012,Qi2012}.}  
We also investigate more complex supervised
approaches, namely Random Forest (RF), as for example Locke {\it et al.}~\cite{Locke2015} showed in a recent meta-study
around genetic susceptibility to obesity that only five of the 97 genomic loci have an independent association signal
the rest seem to jointly predict the complex metabolic phenotype.  We therefore investigate whether ethnicity is a
similarly complex phenotype that requires higher order dependencies between features to be taken into
account. %, as done by RF and DL.

RF inherit many of the benefits of decision trees. It handles large numbers of variables transparently and
provides an unbiased estimate of the generalization error (in addition, it handles missing values and unbalanced
population classes sizes). They provide a measure of variable importance and allow for interactions between
variables to be investigated. However, in this problem, with many millions of variables, inspecting plots of interactions
is not feasible.  We note that decision trees (and random forests) model local variable interactions -- there are 
no main effects or global interaction effects. 

For shallow neural networks there are a number of methods for controlling overfitting including regularization, max norm
constraints, and dropout. Whether the problem of overfitting is exacerbated or not in deep networks is an open problem.
With a large number of variables (like this problem) some regularization is going to be necesssary. 
%http://stats.stackexchange.com/questions/21152/obtaining-knowledge-from-a-random-forest

However, training a supervised learning method on such an expansive dataset as the 1000 genomes is computationally 
challenging and traditional massively parallel approaches to data processing are not easily applicable to machine learning 
tasks, as they iteratively refine models based on information from the full dataset.

We therefore use {\sc Spark} through our recently developed \variantSpark~\cite{OBrien} framework, which allows us to
apply machine learning algorithms in the {\sc MLlib} library to the variant file in the standard Variant Call Format (VCF) format.  Please note
that unlike {\sc Hadoop}, {\sc Spark} allows a more flexible software design to utilise node-parallelisation and offers
in-memory cashing, both critical components for efficient ``big learning" tasks.

To demonstrate \variantSpark's capability, we determine the cross-validation accuracy of the supervised multivariate RF
method and compare it against the simple supervised method LR as well as the unsupervised \kMeans{} in the first
section.  In the second section we compare LR and \kMeans{} against the reported accuracy of the supervised multivariate
deep learning (DL) method.  In section three we record the accuracy of LR and \kMeans{} on the full dataset set using all populations.
In the last section we discuss the memory consumptions and runtime of LR compared to \kMeans{}.

\clearpage
\hrule
I think the use of the term ``multivariate'' is a bit loose. We have only one $y$ variable -- obesity. By analogy with linear regression:
\begin{itemize}
\item simple linear regression $y=\beta_0 + \beta_1x_1$
\item multi-variable regression $y=\beta_0 + \beta_1x_1 + \beta_2 x_2$
\item multivariate regression $\underset{n\times m}{Y}= \underset{(n\times p+1)}{X} \underset{(p+1 \times m)}{B}$
\end{itemize}
So RF, DL and LR are all multi-variable (in this application). 

A multivarite technique we could use is PCA, $T = X W$ where $W$ is a $p \times p$ matrix whose columns are the eigenvectors of $X^tX$. 
\hrule

\section{Results}

\subsubsection{Random Forest does not scale to whole genome analysis and is outperformed by logistic regression}
In this section we compare RF against \kMeans\ and the LR.  
Despite using {\sc Spark} and {\sc MLlib}, RF is not able to scale to the full dataset of 1000 individuals and 40
Million variables, due to a limitation of the Java virtual machine (maximum array size) that causes {\sc Mllib}'s
random forest implementation to fail. This error is due to the number of features present in each sample,
with a potential solution being to limit the features through feature selection, or simply using a subset of the dataset.
We therefore use only chromosome 22 (494,328 alleles) for the comparison in this section.  We train a RF
and LR on this subset of genomic profiles from the 1000 Genomes data using the annotated labels of all
super-populations.  We perform 10-fold cross-validation and report the mean error over all training and testing folds
along with the standard error of the mean (SEM). We also use the Adjusted Rand Index (ARI) as a metric for model quality
as it allows us to compare the classification results with \kMeans{} clustering models. We also calculate the error
for the two classification methods, which is simply the number of misclassified individuals divided by the number of samples.
We perform 10 runs of \kMeans{} with 4 clusters (\(k=4\)) and report the mean ARI of the
resulting models along with the standard error.

As reported in our earlier work, \kMeans\ is not able to fit the dataset accurately, with an average ARI over ten models of \(0.596 \pm 0.067\), see table~\ref{RF}.
%Although capable of fitting a relatively accurate model (\(ARI=0.837\)), The average ARI over ten models is  \(0.596 \pm 0.067\), see table~\ref{RF}.
RF achieves a better fitting model with a mean ARI of \(0.769 \pm 0.021\), however it is outperformed by the LR, with an ARI of \(0.923 \pm 0.015\).
This indicates that while applying a supervised learning method results in higher accuracy, a multivariate approach may not be needed to accurately fit ethnicity. 


\begin{table}
\caption{Cross-validated results, ARI and error (and standard error of mean) on variants from chromosome 22 of 4 super-populations.}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & ARI & error \\
RF  & 0.769 (0.021) &0.118 (0.011) \\
\kMeans & 0.596 (0.067) & -- \\
LR & 0.923 (0.015) & 0.034 (0.006) \\
\noalign{\smallskip}
\hline
\label{RF}
\end{tabular}
\end{center}
\end{table}

%These results also demonstrate how much the quality of the models can vary between runs (or folds) for supervised and unsupervised learning.
%For both of the supervised methods, RF and LR, the ARI was fairly consistent when testing on each holdout set, with a standard deviation of
%\( 0.064 \) and 0.048, respectively. For the \kMeans{} models however, the standard deviation was 0.211.
%One pitfall of \kMeans{} clustering is that depending on the starting points, the resulting model may represent a local optimum of the dataset~\cite{Steinley2003}.
%{\sc MLlib} uses {\sc \kMeans\textbar\textbar}~\cite{Bahmani2012} (a parallel implementation of \kMeans{}++) for the cluster initialisation.
%Although this produces close to the optimal solution for the initial cluster centres, due to the heuristical nature of the algorithm,
%these initial cluster centres will be different for each model. Due to the amount of variance in the 1000 Genomes dataset, it is possible that multiple local
%optima are close to the global optimum, and the algorithm is choosing one that does not represent population structure.

\subsubsection{Logistic regression and \kMeans{} capture the population better than deep learning in a three population test}
In this section we investigate whether another multivariate approach, DL, is able to achieve a better result than
RF by again comparing it against \kMeans{} and logistic regression.  We compare against the reported accuracy of the
deep learning approach using the {\sc ADAM} framework~\cite{Massie2013} as reported on their webpage~\cite{Ferguson}.
As the reported results were performed on only three of the 14 populations, we hence restrict our comparison also to ASW
(Americans of African Ancestry in SW USA), CHB (Han Chinese in Beijing, China), and GBR (British in England and
Scotland).

The mean ARI for our \kMeans{} clustering models on this dataset is \(0.960 \pm 0.004 \). 
This value is slightly less than the one reported for the deep-learning approach, which achieved an ARI of 0.976 (where one ASW and one GBR individual are misclassified as CHB). 
Our supervised logistic regression approach, however, improves upon this result and achieves an ARI of 1 across the ten folds.

Although we see a slight improvement with logistic regression in regards to other algorithms, their results are still very similar.
However, there is not much room in the first place for logistic regression to demonstrate any potential increases in model accuracy.
We therefore proceed to apply our method to the entire 1000 Genomes Project phase 1 dataset, which we previously clustered with an ARI of 0.84.


\begin{table}
\caption{Cross-validated results, mean accuracy (and standard error) on 3 populations.}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & ARI & error \\
LR  & 1.000 (0.000) & 0.000 \\
\kMeans & 0.960 (0.004) & -- \\
deep learning & 0.976 & 0.008 \\
\noalign{\smallskip}
\hline
\end{tabular}
\end{center}
\end{table}


\subsubsection{Logistic regression is more accurate than \kMeans{} in capturing the full population structure}
In this section we apply both the supervised LR and unsupervised \kMeans\ method on the full dataset of 14 populations and assess the 
classification accuracy into the 4 super-populations.
Using 10-fold cross-validation to assess the logistic regression classification results, we observe an average ARI of \(0.936 \pm{} 0.014\).
%DENIS: above you argue that kMeans has local optima and results might hence be too optimistic but here you only train one model. So either remove the above section or add some repeats to this one
This is an improvement on our previous result from \kMeans{} clustering the same dataset in our previous work, where we observed an ARI of \(0.83\).

\begin{table}
\caption{Cross-validated results, mean accuracy (and standard error) on the 4 super-populations.}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & ARI & error \\
LR  & 0.936 (0.014) & 0.029 (0.005) \\
\kMeans & 0.84 & -- \\
\noalign{\smallskip}
\hline
\end{tabular}
\end{center}
\end{table}

To determine where the model is underperforming, we also record the precision and recall for each of the groups.
We observe that for each model, the precision and recall are always 1.0 for the EAS super-population.
This demonstrates that each logistic regression model was able to classify every EAS individual correctly, while not misclassifying any other individuals as EAS.
For the AMR group, however, we consistently observed a relatively low precision (\(0.829 \pm{} 0.02 \)).
This is due to individuals from the AFR and EUR super-populations being misclassified as AMR.
Consequently, this leds to these two super-populations having a lower recall of \(0.956 \pm 0.01 \) and \(0.950 \pm 0.02 \), respectively.
Although these misclassifications as AMR are relatively frequent, we did not observe any AFR individuals being classified as EUR, or {\it vice versa}, in any of the ten folds.
Also, only in one fold did we observe one AMR individual misclassified as another super-population (AFR).
These results demonstrate the diversity, or relative difference of some of the groups. 

\begin{table}
\caption{Mean precision and recall (and standard error of mean) for each super-population across the ten logistic regression folds.}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
super-population  & precision & recall \\
AFR  & 0.997 (0.003) & 0.956 (0.013) \\
AMR & 0.829 (0.020) & 0.994 (0.005) \\
EAS  & 1 (0) & 1 (0) \\
EUR  & 1 (0) & 0.950 (0.015) \\
\noalign{\smallskip}
\hline
\end{tabular}
\end{center}
\end{table}







\subsubsection{\kMeans{} clustering is faster and consumes less memory than random forests}

Time and resources vary greatly between the three algorithms, with the most resource intensive being random forests.
This is likely due to RF being an ensemble method. Where logistic regression and \kMeans{} clustering build a single model,
RF is building an forest of decision trees. So not only is training longer, but then each sample in the test fold must be classified by each and every tree.

LR is 



\marginpar{TODO [write up the observations and argue why one is less resource hungry than the other one]}


\begin{table}
\caption{Runtime and memory consumption on the 4 super-populations}
\begin{center}
\renewcommand{\arraystretch}{1.4}
\setlength\tabcolsep{3pt}
\begin{tabular}{lcccc}
\hline\noalign{\smallskip}
method  & nodes & runtime & memory \\
RF  & X (Y) & X (Y) & X (Y) \\
\kMeans & X (Y) & X (Y) & X (Y) \\
\noalign{\smallskip}
\hline
\end{tabular}
\end{center}
\end{table}




\section{Conclusion}
In this paper we systematically investigated the performance of supervised and unsupervised methods for determining the
ethnicity from whole genome variant data.  We found that a supervised method, logistic regression, outperforms the
unsupervised approach, \kMeans{} (0.936 vs 0.84).  We also found that ethnicity can be better predicted by the simple
logistic regression method compared to the 
%unsupervised \kMeans{} approach or the 
multivariate random forest or deep learning approach as reported by
Big Data Genomics using the ADAM framework (1 vs 0.96 and 0.976, respectively).  Furthermore, we observe a limitation within
Java, which limits the random forest implementation of {\sc Spark}'s {\sc MLlib} to XX features for the 1069 individuals
of the 1000 genome project.  This property would make feature selection mandatory for the 100,000 genome project when classifying their
70,000 individuals, when using the same random forest implementation.  We conclude that while logistic regression
outperforms all other methods it remains unable to accurately identify all individuals from EUR (lowest precision) or misclassify AMR (lowest recall) individuals. 
We therefore ague that the remaining mixture is potentially reflective of the migrational background, which may be an important observation for medical
applications that need accurate population association.



%DENIS - does recomb paper need a method section ??


\bibliographystyle{my_plain}
<<<<<<< HEAD
\marginpar{FIXED:  TODO you need to find a way of shortening the Locket paper author list}
=======
>>>>>>> 7fcbff9a5610e2b12c8ab5d74fb6874328651beb
\bibliography{recomb}  

\end{document}
